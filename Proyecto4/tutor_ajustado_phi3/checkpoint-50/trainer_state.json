{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9801980198019802,
  "eval_steps": 500,
  "global_step": 50,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04,
      "learning_rate": 0.00019733333333333335,
      "loss": 1.2303,
      "step": 1
    },
    {
      "epoch": 0.08,
      "learning_rate": 0.0001946666666666667,
      "loss": 1.1206,
      "step": 2
    },
    {
      "epoch": 0.12,
      "learning_rate": 0.000192,
      "loss": 1.2335,
      "step": 3
    },
    {
      "epoch": 0.16,
      "learning_rate": 0.00018933333333333335,
      "loss": 1.4292,
      "step": 4
    },
    {
      "epoch": 0.2,
      "learning_rate": 0.0001866666666666667,
      "loss": 1.4173,
      "step": 5
    },
    {
      "epoch": 0.24,
      "learning_rate": 0.00018400000000000003,
      "loss": 1.1977,
      "step": 6
    },
    {
      "epoch": 0.28,
      "learning_rate": 0.00018133333333333334,
      "loss": 0.9368,
      "step": 7
    },
    {
      "epoch": 0.32,
      "learning_rate": 0.00017866666666666668,
      "loss": 1.0345,
      "step": 8
    },
    {
      "epoch": 0.36,
      "learning_rate": 0.00017600000000000002,
      "loss": 0.7819,
      "step": 9
    },
    {
      "epoch": 0.4,
      "learning_rate": 0.00017333333333333334,
      "loss": 1.3828,
      "step": 10
    },
    {
      "epoch": 0.44,
      "learning_rate": 0.00017066666666666668,
      "loss": 1.1858,
      "step": 11
    },
    {
      "epoch": 0.48,
      "learning_rate": 0.000168,
      "loss": 0.8352,
      "step": 12
    },
    {
      "epoch": 0.51,
      "learning_rate": 0.00016533333333333333,
      "loss": 1.1909,
      "step": 13
    },
    {
      "epoch": 0.55,
      "learning_rate": 0.00016266666666666667,
      "loss": 0.643,
      "step": 14
    },
    {
      "epoch": 0.59,
      "learning_rate": 0.00016,
      "loss": 0.8619,
      "step": 15
    },
    {
      "epoch": 0.63,
      "learning_rate": 0.00015733333333333333,
      "loss": 0.9238,
      "step": 16
    },
    {
      "epoch": 0.67,
      "learning_rate": 0.00015466666666666667,
      "loss": 0.819,
      "step": 17
    },
    {
      "epoch": 0.71,
      "learning_rate": 0.000152,
      "loss": 0.8159,
      "step": 18
    },
    {
      "epoch": 0.75,
      "learning_rate": 0.00014933333333333335,
      "loss": 0.7291,
      "step": 19
    },
    {
      "epoch": 0.79,
      "learning_rate": 0.00014666666666666666,
      "loss": 0.8244,
      "step": 20
    },
    {
      "epoch": 0.83,
      "learning_rate": 0.000144,
      "loss": 0.8071,
      "step": 21
    },
    {
      "epoch": 0.87,
      "learning_rate": 0.00014133333333333334,
      "loss": 0.9063,
      "step": 22
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00013866666666666669,
      "loss": 0.7444,
      "step": 23
    },
    {
      "epoch": 0.95,
      "learning_rate": 0.00013600000000000003,
      "loss": 0.7804,
      "step": 24
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.5717,
      "step": 25
    },
    {
      "epoch": 1.03,
      "learning_rate": 0.00013066666666666668,
      "loss": 0.8586,
      "step": 26
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00012800000000000002,
      "loss": 0.5882,
      "step": 27
    },
    {
      "epoch": 1.11,
      "learning_rate": 0.00012533333333333334,
      "loss": 0.6121,
      "step": 28
    },
    {
      "epoch": 1.15,
      "learning_rate": 0.00012266666666666668,
      "loss": 0.3515,
      "step": 29
    },
    {
      "epoch": 1.19,
      "learning_rate": 0.00012,
      "loss": 0.6642,
      "step": 30
    },
    {
      "epoch": 1.23,
      "learning_rate": 0.00011733333333333334,
      "loss": 0.7464,
      "step": 31
    },
    {
      "epoch": 1.27,
      "learning_rate": 0.00011466666666666667,
      "loss": 0.4837,
      "step": 32
    },
    {
      "epoch": 1.31,
      "learning_rate": 0.00011200000000000001,
      "loss": 0.7214,
      "step": 33
    },
    {
      "epoch": 1.35,
      "learning_rate": 0.00010933333333333333,
      "loss": 0.6714,
      "step": 34
    },
    {
      "epoch": 1.39,
      "learning_rate": 0.00010666666666666667,
      "loss": 0.6358,
      "step": 35
    },
    {
      "epoch": 1.43,
      "learning_rate": 0.00010400000000000001,
      "loss": 0.7783,
      "step": 36
    },
    {
      "epoch": 1.47,
      "learning_rate": 0.00010133333333333335,
      "loss": 0.5857,
      "step": 37
    },
    {
      "epoch": 1.5,
      "learning_rate": 9.866666666666668e-05,
      "loss": 0.5702,
      "step": 38
    },
    {
      "epoch": 1.54,
      "learning_rate": 9.6e-05,
      "loss": 0.3067,
      "step": 39
    },
    {
      "epoch": 1.58,
      "learning_rate": 9.333333333333334e-05,
      "loss": 0.5876,
      "step": 40
    },
    {
      "epoch": 1.62,
      "learning_rate": 9.066666666666667e-05,
      "loss": 0.6981,
      "step": 41
    },
    {
      "epoch": 1.66,
      "learning_rate": 8.800000000000001e-05,
      "loss": 0.5559,
      "step": 42
    },
    {
      "epoch": 1.7,
      "learning_rate": 8.533333333333334e-05,
      "loss": 0.5413,
      "step": 43
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.266666666666667e-05,
      "loss": 0.5817,
      "step": 44
    },
    {
      "epoch": 1.78,
      "learning_rate": 8e-05,
      "loss": 0.521,
      "step": 45
    },
    {
      "epoch": 1.82,
      "learning_rate": 7.733333333333333e-05,
      "loss": 0.6083,
      "step": 46
    },
    {
      "epoch": 1.86,
      "learning_rate": 7.466666666666667e-05,
      "loss": 0.3339,
      "step": 47
    },
    {
      "epoch": 1.9,
      "learning_rate": 7.2e-05,
      "loss": 0.4356,
      "step": 48
    },
    {
      "epoch": 1.94,
      "learning_rate": 6.933333333333334e-05,
      "loss": 0.7699,
      "step": 49
    },
    {
      "epoch": 1.98,
      "learning_rate": 6.666666666666667e-05,
      "loss": 0.4359,
      "step": 50
    }
  ],
  "logging_steps": 1,
  "max_steps": 75,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "total_flos": 385058288443392.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
